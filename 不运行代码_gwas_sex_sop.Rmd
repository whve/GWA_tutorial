---
title: "gwas_sex_sop"
output: html_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
# ,eval=FALSE
# knitr::opts_chunk$set(engine.opts = list(bash = "-l"))

knitr::opts_chunk$set(engine.opts='-l')

```

## data ready
```{bash,eval=FALSE}
# unzip
unzip 1_QC_GWAS.zip # or unzip \*.zip
#replace 1_QC_GWAS/1_Main_script_QC_GWAS.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: 

```

## Introduction

The tutorial consist of four separate parts. The first three are dependent of each other and can only be performed in consecutive order, starting from the first (1_QC_GWAS.zip), then the second (2_Population_stratification.zip, followed by the third (3_Association_GWAS). The fourth part (4_ PRS.doc) can be performed independently. 

The Unix commands provided in this guide should be typed/copy-and-pasted after the prompt ($ or >) on your Unix machine. Note, the ">" in front of the commands should not be copy-and-pasted. Only what comes after the ">".

We assume that you have read the accompanying article "A tutorial on conducting Genome-Wide-Association Studies: Quality control and statistical analysis
" (https://www.ncbi.nlm.nih.gov/pubmed/29484742), which should provide you with a basic theoretical understanding of the type of analyses covered in this tutorial. 

This step-by-step guide serves researchers who have none or very little experience with Unix, by helping them through the Unix commands in preparation of the tutorial. 


## Preparation

Step 1) The current set of tutorials on this GitHub page are based on a GNU/Linux-based computer, therefore: 
- Make sure you have access to a GNU/Linux-based computer resource.
- Create a directory where you plan to conduct the analysis.
#### Execute the command below (copy-and-paste without the prompt: > and without the {} ).

```{bash,eval=FALSE}

mkdir project_gwas_sop #{name_for_your_directory}


```



Step 2) Download the files from the GitHub page 
- Change the directory of your Unix machine to the created directory from step 1.
#### Execute the command below
> cd HOME/{user}/{path/name_for_your_directory}  
> git clone https://github.com/MareesAT/GWA_tutorial.git

- Unzip the folder of the first tutorial and move into the newly created directory.
#### Execute the commands below
> unzip 1_QC_GWAS.zip
> cd 1_QC_GWAS
<br />

Step 3) This tutorial requires the open-source programming language R and the open-source whole genome association analysis toolset PLINK version 1.07 (all commands also work with PLINK2). If these programs are not already installed on your computer they can be downloaded from respectively:
https://www.r-project.org/
http://zzz.bwh.harvard.edu/plink/
https://www.cog-genomics.org/plink2

- We recommend using the newest versions. These websites will guide you through the installation process.

- Congratulations everything is set up to start the tutorial!


## Execution of tutorial 1

Step 4) Once you've created a directory in which you have downloaded and unzipped the folder: 1_QC_GWAS.zip, you are ready to start the first part of the actual tutorial.
All steps of this tutorial will be excecuted using the commands from the main script: 1_Main_script_QC_GWAS.txt, the only thing necessary in completing the tutorial is copy-and-paste the commands from the main script at the prompt of your Unix device. Note, make sure you are in the directory containing all files, which is the directory after the last command of step 2. There is no need to open the other files manually. 

There are two ways to use the main script:  
#### Option 1
- If you are a novice user, we recommend opening 1_Main_script_QC_GWAS.txt in WordPad or Notepad on your Windows computer.

#### Option 2
- Alternatively, 1_Main_script_QC_GWAS.txt can be opened using an Unix text editor, for example vi.
#### Open the main script with vi :
> vi 1_Main_script_QC_GWAS.txt
- This enables you to read the script within the Unix environment and copy the command lines from it.
#### To exit vi and return to your directory use: 
> :q

- From there, using either option 1 or 2, you can read the information given at every step of script â€œ, 1_Main_script_QC_GWAS.txtâ€ and copy-paste the commands after the prompt on your Unix machine. 

Note, if R or PLINK are installed in a directory other than your working directory please specify the path to the excecutables in the given script. Alternatively, you can copy the executables of the programs to your working directory. For example, by using:
cp {path/program name} {path/directiory}. However, when using a cluster computer, commands such a "module load plink", and "module load R" will suffice, regardless of directory.

For more information of using R and PLINK in a Unix/Linux environment we refer to:
http://zzz.bwh.harvard.edu/plink/download.shtml#nixs
## 1_Main_script_QC_GWAS.txt

```{r,eval=FALSE}
# test ä¸€è¡Œä¸€è¡Œè¿è¡Œ cmd + enter/ crtl +enter, only R?
print("1")

print("2")

```


```{bash,eval=FALSE}
# test |,engine.opts='-l'
pwd
pwd
plink
```

```{bash, eval=FALSE}

################ Explanation of the main script ##########################

# This tutorial uses freely available HapMap data: hapmap3_r3_b36_fwd.consensus.qc. We simulated a binary outcome measure (i.e., a binary phenotypic trait) and added this to the dataset. The outcome measure was only simulated for the founders in the HapMap data. This data set will be referred to as HapMap_3_r3_1. 
# The HapMap data, without our simulated outcome measure, can also be obtained from http://hapmap.ncbi.nlm.nih.gov/downloads/genotypes/2010-05_phaseIII/plink_format/ 
# It is essential for the execution of the tutorial that that all scripts belonging to this tutorial are in the same directory on your UNIX workstation.
# Many scripts include comments which explain how these scripts work. Note, in order to complete the tutorial it is essential to execute all commands in this tutorial.
# This script can also be used for your own data analysis, to use it as such, replace the name of the HapMap file with the name of your own data file. 
# Furthermore, this script is based on a binary outcome measure, and is therefore not applicable for quantitative outcome measures (this would require some adaptations)
# Note, most GWAS studies are performed on an ethnic homogenous population, in which population outliers are removed. The HapMap data, used for this tutorial, contains multiple distinct ethnic groups, which makes it problematic for analysis.
# Therefore, we have selected only the EUR individuals of the complete HapMap sample for the tutorials 1-3. This selection is already performed in the HapMap_3_r3_1 file from our GitHub page.
# The Rscripts used in this tutorial are all executed from the Unix command line.
# Therefore, this tutorial and the other tutorials from our GitHub page, can be completed simply by copy-and-pasting all commands from the ?main scripts? into the Unix terminal.
# For a thorough theoretical explanation of all QC steps we refer to the article accompanying this tutorial entitled ?A tutorial on conducting Genome-Wide-Association Studies: Quality control and statistical analysis? (https://www.ncbi.nlm.nih.gov/pubmed/29484742).


##############################################################
############### START ANALISIS ###############################
##############################################################

# Change directory to a folder on your UNIX device containing all files from ?1_QC_GWAS.zip?. 
pwd
```

```{bash,eval=FALSE}
cd 1_QC_GWAS
pwd

```
æ•°æ®å‡†å¤‡ï¼Œ *plinkï¼Œ pops_*
```{bash,eval=FALSE}
### Step 1 ### 
cd /home/wangzhe/projects/20220629_GWA_tutorial/1_QC_GWAS
# Investigate missingness per individual and per SNP and make histograms.
plink --bfile HapMap_3_r3_1 --missing    
# output: plink.imiss and plink.lmiss, these files show respectively the proportion of missing SNPs per individual and the proportion of missing individuals per SNP.


# Generate plots to visualize the missingness results.
Rscript --no-save hist_miss.R

# Delete SNPs and individuals with high levels of missingness, explanation of this and all following steps can be found in box 1 and table 1 of the article mentioned in the comments of this script.
# The following two QC commands will not remove any SNPs or individuals. However, it is good practice to start the QC with these non-stringent thresholds.  
# Delete SNPs with missingness >0.2.
plink --bfile HapMap_3_r3_1 --geno 0.2 --make-bed --out HapMap_3_r3_2

# Delete individuals with missingness >0.2.
plink --bfile HapMap_3_r3_2 --mind 0.2 --make-bed --out HapMap_3_r3_3

# Delete SNPs with missingness >0.02.
plink --bfile HapMap_3_r3_3 --geno 0.02 --make-bed --out HapMap_3_r3_4

# Delete individuals with missingness >0.02.
plink --bfile HapMap_3_r3_4 --mind 0.02 --make-bed --out HapMap_3_r3_5
```
## GWAS åŸºå› å‹æ•°æ®è´¨æ§

--geno ç­›é€‰ SNPï¼›--mind ç­›é€‰ä¸ªä½“

GWAS åˆ†ææ—¶ï¼Œæ‹¿åˆ°åŸºå› å‹æ•°æ®ï¼Œæ‹¿åˆ°è¡¨å‹æ•°æ®ï¼Œè¦é¦–å…ˆåšä»¥ä¸‹å‡ ç‚¹ï¼š
â€¢ 1ï¼ŒæŸ¥çœ‹è‡ªå·±çš„è¡¨å‹æ•°æ®ï¼Œæ˜¯å¦æœ‰é—®é¢˜
â€¢ 2ï¼ŒæŸ¥çœ‹è‡ªå·±çš„åŸºå› å‹æ•°æ®ï¼Œæ˜¯å¦æœ‰é—®é¢˜
æ•°æ®ä½¿ç”¨ä¸Šä¸€ç¯‡çš„æ•°æ®ï¼Œå› ä¸ºæ•°æ®æ˜¯ plink çš„ bfile æ ¼å¼ï¼ŒäºŒè¿›åˆ¶ä¸æ–¹ä¾¿æŸ¥çœ‹ï¼Œæˆ‘
ä»¬å°†å…¶è½¬åŒ–ä¸ºæ–‡æœ¬ map å’Œ ped çš„æ ¼å¼ã€‚
ç»“æœç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶ï¼Œåˆ†åˆ«æ˜¯ä¸€ä¸ªä¸ªä½“ ID ä¸Š SNP ç¼ºå¤±çš„ä¿¡æ¯ï¼Œå¦ä¸€ä¸ªæ˜¯æ¯ä¸ª SNP
åœ¨ä¸ªä½“ ID ä¸­ç¼ºå¤±çš„ä¿¡æ¯ã€‚
â€¢ ä¸ªä½“ç¼ºå¤±ä½ç‚¹çš„ç»Ÿè®¡åœ¨ plink.imiss ä¸­
â€¢ å•ä¸ª SNP ç¼ºå¤±çš„ä¸ªä½“æ•°åœ¨ plink.lmiss.ä¸­
ã€Œä¸ªä½“ç¼ºå¤±ä½ç‚¹ç»Ÿè®¡é¢„è§ˆï¼šã€ç¬¬ä¸€åˆ—ä¸ºå®¶ç³» IDï¼Œç¬¬äºŒåˆ—ä¸ºä¸ªä½“ IDï¼Œç¬¬ä¸‰åˆ—æ˜¯å¦è¡¨
å‹ç¼ºå¤±ï¼Œç¬¬å››åˆ—ç¼ºå¤±çš„ SNP ä¸ªæ•°ï¼Œç¬¬äº”åˆ—æ€» SNP ä¸ªæ•°ï¼Œç¬¬å…­åˆ—ç¼ºå¤±ç‡ã€‚

```{bash,eval=FALSE}
cd 1_QC_GWAS
plink --bfile HapMap_3_r3_1 --recode --out test
wc -l test.map test.ped #165 ä¸ªåŸºå› å‹ä¸ªä½“ï¼Œå…±æœ‰ 1447897 ä¸ª SNP æ•°æ®
#æŸ¥çœ‹ä¸€ä¸‹ä¸ªä½“ç¼ºå¤±çš„ä½ç‚¹æ•°ï¼Œæ¯ä¸ª SNP ç¼ºå¤±çš„ä¸ªä½“æ•°
plink --file test --missing
```






### Step2 #### æ€§åˆ«è´¨æ§
```{bash,eval=FALSE}
###################################################################
### Step2 ####
cd 1_QC_GWAS
# Check for sex discrepancy.
# Subjects who were a priori determined as females must have a F value of <0.2, and subjects who were a priori determined as males must have a F value >0.8. This F value is based on the X chromosome inbreeding (homozygosity) estimate.
# Subjects who do not fulfil these requirements are flagged "PROBLEM" by PLINK.

plink --bfile HapMap_3_r3_5 --check-sex 

# Generate plots to visualize the sex-check results.
Rscript --no-save gender_check.R
# These checks indicate that there is one woman with a sex discrepancy, F value of 0.99. (When using other datasets often a few discrepancies will be found). 

# The following two scripts can be used to deal with individuals with a sex discrepancy.
# Note, please use one of the two options below to generate the bfile hapmap_r23a_6, this file we will use in the next step of this tutorial.

# 1) Delete individuals with sex discrepancy.#ä½¿ç”¨ remove å»æ‰ä¸ªä½“
grep "PROBLEM" plink.sexcheck| awk '{print$1,$2}'> sex_discrepancy.txt
# This command generates a list of individuals with the status ?PROBLEM?.
plink --bfile HapMap_3_r3_5 --remove sex_discrepancy.txt --make-bed --out HapMap_3_r3_6 
# This command removes the list of individuals with the status ?PROBLEM?.

# 2) impute-sex.# å¯¹ä¸ªä½“è¿›è¡Œåˆ¤å®šå¡«å……
#plink --bfile HapMap_3_r3_5 --impute-sex --make-bed --out HapMap_3_r3_6
# This imputes the sex based on the genotype information into your data set.
```
### Step 3 ### MAFè´¨æ§ -> 22+Xå·æŸ“è‰²ä½“ğŸ§¬
```{bash,eval=FALSE}
###################################################
### Step 3 ### 
cd 1_QC_GWAS
# Generate a bfile with autosomal SNPs only and delete SNPs with a low minor allele frequency (MAF).

# Select autosomal SNPs only (i.e., from chromosomes 1 to 22).# 22 -> 23
# awk '{ if ($1 >= 1 && $1 <= 22) print $2 }' HapMap_3_r3_6.bim > snp_1_22.txt
awk '{ if ($1 >= 1 && $1 <= 23) print $2 }' HapMap_3_r3_6.bim > snp_1_23.txt
# plink --bfile HapMap_3_r3_6 --extract snp_1_22.txt --make-bed --out HapMap_3_r3_7
plink --bfile HapMap_3_r3_6 --extract snp_1_23.txt --make-bed --out HapMap_3_r3_7
# Generate a plot of the MAF distribution.
plink --bfile HapMap_3_r3_7 --freq --out MAF_check
Rscript --no-save MAF_check.R

# Remove SNPs with a low MAF frequency.
plink --bfile HapMap_3_r3_7 --maf 0.05 --make-bed --out HapMap_3_r3_8
# 1073226 SNPs are left
# A conventional MAF threshold for a regular GWAS is between 0.01 or 0.05, depending on sample size.
```



####################################################
### Step 4 ### æ•°æ®è´¨æ§ï¼šå“ˆæ¸©å¹³è¡¡
```{bash,eval=FALSE}
cd 1_QC_GWAS
# Delete SNPs which are not in Hardy-Weinberg equilibrium (HWE).
# Check the distribution of HWE p-values of all SNPs.

plink --bfile HapMap_3_r3_8 --hardy
# Selecting SNPs with HWE p-value below 0.00001, required for one of the two plot generated by the next Rscript, allows to zoom in on strongly deviating SNPs. 
awk '{ if ($9 <0.00001) print $0 }' plink.hwe>plinkzoomhwe.hwe
Rscript --no-save hwe.R

# By default the --hwe option in plink only filters for controls.
# Therefore, we use two steps, first we use a stringent HWE threshold for controls, followed by a less stringent threshold for the case data.
plink --bfile HapMap_3_r3_8 --hwe 1e-6 --make-bed --out HapMap_hwe_filter_step1

# The HWE threshold for the cases filters out only SNPs which deviate extremely from HWE. 
# This second HWE step only focusses on cases because in the controls all SNPs with a HWE p-value < hwe 1e-6 were already removed
plink --bfile HapMap_hwe_filter_step1 --hwe 1e-10 --hwe-all --make-bed --out HapMap_3_r3_9

# Theoretical background for this step is given in our accompanying article: https://www.ncbi.nlm.nih.gov/pubmed/29484742 .
```
############################################################
### step 5 ### æ•°æ®è´¨æ§ï¼šæ‚åˆåº¦è´¨æ§
```{bash,eval=FALSE}
# Generate a plot of the distribution of the heterozygosity rate of your subjects.
# And remove individuals with a heterozygosity rate deviating more than 3 sd from the mean.

# Checks for heterozygosity are performed on a set of SNPs which are not highly correlated.
# Therefore, to generate a list of non-(highly)correlated SNPs, we exclude high inversion regions (inversion.txt [High LD regions]) and prune the SNPs using the command --indep-pairwise?.
# The parameters ?50 5 0.2? stand respectively for: the window size, the number of SNPs to shift the window at each step, and the multiple correlation coefficient for a SNP being regressed on all other SNPs simultaneously.
cd 1_QC_GWAS
plink --bfile HapMap_3_r3_9 --exclude inversion.txt --range --indep-pairwise 50 5 0.2 --out indepSNP
# Note, don't delete the file indepSNP.prune.in, we will use this file in later steps of the tutorial.

plink --bfile HapMap_3_r3_9 --extract indepSNP.prune.in --het --out R_check
# This file contains your pruned data set.

# Plot of the heterozygosity rate distribution
Rscript --no-save check_heterozygosity_rate.R

# The following code generates a list of individuals who deviate more than 3 standard deviations from the heterozygosity rate mean.
# For data manipulation we recommend using UNIX. However, when performing statistical calculations R might be more convenient, hence the use of the Rscript for this step:
Rscript --no-save heterozygosity_outliers_list.R

# Output of the command above: fail-het-qc.txt .
# When using our example data/the HapMap data this list contains 2 individuals (i.e., two individuals have a heterozygosity rate deviating more than 3 SD's from the mean).
# Adapt this file to make it compatible for PLINK, by removing all quotation marks from the file and selecting only the first two columns.
sed 's/"// g' fail-het-qc.txt | awk '{print$1, $2}'> het_fail_ind.txt

# Remove heterozygosity rate outliers.
plink --bfile HapMap_3_r3_9 --remove het_fail_ind.txt --make-bed --out HapMap_3_r3_10
```


############################################################
### step 6 ### æ•°æ®è´¨æ§ï¼šäº²ç¼˜å…³ç³»è¿‡æ»¤|fzbixu
```{bash,eval=FALSE}
# It is essential to check datasets you analyse for cryptic relatedness.
# Assuming a random population sample we are going to exclude all individuals above the pihat threshold of 0.2 in this tutorial.
cd 1_QC_GWAS
# Check for relationships between individuals with a pihat > 0.2.
plink --bfile HapMap_3_r3_10 --extract indepSNP.prune.in --genome --min 0.2 --out pihat_min0.2

# The HapMap dataset is known to contain parent-offspring relations. 
# The following commands will visualize specifically these parent-offspring relations, using the z values. 
awk '{ if ($8 >0.9) print $0 }' pihat_min0.2.genome>zoom_pihat.genome

# Generate a plot to assess the type of relationship.
Rscript --no-save Relatedness.R

# The generated plots show a considerable amount of related individuals (explentation plot; PO = parent-offspring, UN = unrelated individuals) in the Hapmap data, this is expected since the dataset was constructed as such.
# Normally, family based data should be analyzed using specific family based methods. In this tutorial, for demonstrative purposes, we treat the relatedness as cryptic relatedness in a random population sample.
# In this tutorial, we aim to remove all 'relatedness' from our dataset.
# To demonstrate that the majority of the relatedness was due to parent-offspring we only include founders (individuals without parents in the dataset).

plink --bfile HapMap_3_r3_10 --filter-founders --make-bed --out HapMap_3_r3_11

# Now we will look again for individuals with a pihat >0.2.
plink --bfile HapMap_3_r3_11 --extract indepSNP.prune.in --genome --min 0.2 --out pihat_min0.2_in_founders
# The file 'pihat_min0.2_in_founders.genome' shows that, after exclusion of all non-founders, only 1 individual pair with a pihat greater than 0.2 remains in the HapMap data.
# This is likely to be a full sib or DZ twin pair based on the Z values. Noteworthy, they were not given the same family identity (FID) in the HapMap data.

# For each pair of 'related' individuals with a pihat > 0.2, we recommend to remove the individual with the lowest call rate. 
plink --bfile HapMap_3_r3_11 --missing
```

#### cd 1_QC_GWAS
```{bash,eval=FALSE}
cd 1_QC_GWAS
# Use an UNIX text editor (e.g., vi(m) ) to check which individual has the highest call rate in the 'related pair'. 

# Generate a list of FID and IID of the individual(s) with a Pihat above 0.2, to check who had the lower call rate of the pair.
# In our dataset the individual 13291  NA07045 had the lower call rate.
## vi 0.2_low_call_rate_pihat.txt----
## i ----
## 13291  NA07045----
# Press esc on keyboard!
## :x----
# Press enter on keyboard
# In case of multiple 'related' pairs, the list generated above can be extended using the same method as for our lone 'related' pair.

# Delete the individuals with the lowest call rate in 'related' pairs with a pihat > 0.2 
plink --bfile HapMap_3_r3_11 --remove 0.2_low_call_rate_pihat.txt --make-bed --out HapMap_3_r3_12
```
################################################################################################################################
```{bash,eval=FALSE}
# CONGRATULATIONS!! You've just succesfully completed the first tutorial! You are now able to conduct a proper genetic QC. 

# For the next tutorial, using the script: 2_Main_script_MDS.txt, you need the following files:
# - The bfile HapMap_3_r3_12 (i.e., HapMap_3_r3_12.fam,HapMap_3_r3_12.bed, and HapMap_3_r3_12.bim
# - indepSNP.prune.in


```


## Execution of tutorial 2&3

- Unzip the tutorial folder of choice as described in step 2.
- Use the output file from the last tutorial as input for the tutorial you want to start.
#### The command below can be used to copy the file to another directory
> cp {path/directory/file} {path/directory}

- Use 2_Main_script_MDS.txt for the second tutorial and 3_Main_script_association_GWAS.txt for the third tutorial.

## 2_Main_script_MDS.txt |covariate file äººå£åˆ†å±‚
```{bash,eval=FALSE}

################ Explanation of the main script ##########################

# This is the main script for second tutorial from our comprehensive tutorial on GWAS and PRS.
# To run this script the following (b)files from the first tutorial are required: HapMap_3_r3_12 (this bfile contain: HapMap_3_r3_12.fam,HapMap_3_r3_12.bim, and HapMap_3_r3_12.bed; you need all three), and indepSNP.prune.in.
# In this tutorial we are going to check for population stratification.
# We will do this as follows, the bfile (HapMap_3_r3_12) generated at the end of the previous tutorial (1_QC_GWAS) is going to checked for population stratification using data from the 1000 Genomes Project. Individuals with a non-European ethnic background will be removed.
# Furthermore, this tutorial will generate a covariate file which helps to adust for remaining population stratification within the European subjects.
# In order to complete this tutorial it is necessary to have generated the bfile 'HapMap_3_r3_12' and the file 'indepSNP.prune.in' from the previous tutorial.


##############################################################
############### START ANALISIS ###############################
##############################################################

# Copy the (b)files from the previous tutorial to the current directory (see explanation of the main script).
cp 1_QC_GWAS/HapMap_3_r3_12.* 2_Population_stratification
cp 1_QC_GWAS/indepSNP.prune.in 2_Population_stratification
```
```{bash,eval=FALSE}
## Download 1000 Genomes data ##
# This file from the 1000 Genomes contains genetic data of 629 individuals from different ethnic backgrounds.
# Note, this file is quite large (>60 gigabyte).  
##  wget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz
```
# downloadfile togo
```{bash,eval=FALSE}
# Convert vcf to Plink format.
plink --vcf ALL.2of4intersection.20100804.genotypes.vcf.gz --make-bed --out ALL.2of4intersection.20100804.genotypes
# Noteworthy, the file 'ALL.2of4intersection.20100804.genotypes.bim' contains SNPs without an rs-identifier, these SNPs are indicated with ".". This can also be observed in the file 'ALL.2of4intersection.20100804.genotypes.vcf.gz'. To check this file use this command: zmore ALL.2of4intersection.20100804.genotypes.vcf.gz .
# The missing rs-identifiers in the 1000 Genomes data are not a problem for this tutorial.
# However, for good practice, we will assign unique indentifiers to the SNPs with a missing rs-identifier (i.e., the SNPs with ".").
plink --bfile ALL.2of4intersection.20100804.genotypes --set-missing-var-ids @:#[b37]\$1,\$2 --make-bed --out ALL.2of4intersection.20100804.genotypes_no_missing_IDs

## QC on 1000 Genomes data.
# Remove variants based on missing genotype data.
plink --bfile ALL.2of4intersection.20100804.genotypes_no_missing_IDs --geno 0.2 --allow-no-sex --make-bed --out 1kG_MDS

# Remove individuals based on missing genotype data.
plink --bfile 1kG_MDS --mind 0.2 --allow-no-sex --make-bed --out 1kG_MDS2

# Remove variants based on missing genotype data.
plink --bfile 1kG_MDS2 --geno 0.02 --allow-no-sex --make-bed --out 1kG_MDS3

# Remove individuals based on missing genotype data.
plink --bfile 1kG_MDS3 --mind 0.02 --allow-no-sex --make-bed --out 1kG_MDS4

# Remove variants based on MAF.
plink --bfile 1kG_MDS4 --maf 0.05 --allow-no-sex --make-bed --out 1kG_MDS5

# Extract the variants present in HapMap dataset from the 1000 genomes dataset.
awk '{print$2}' HapMap_3_r3_12.bim > HapMap_SNPs.txt
plink --bfile 1kG_MDS5 --extract HapMap_SNPs.txt --make-bed --out 1kG_MDS6

# Extract the variants present in 1000 Genomes dataset from the HapMap dataset.
awk '{print$2}' 1kG_MDS6.bim > 1kG_MDS6_SNPs.txt
plink --bfile HapMap_3_r3_12 --extract 1kG_MDS6_SNPs.txt --recode --make-bed --out HapMap_MDS
# The datasets now contain the exact same variants.

## The datasets must have the same build. Change the build 1000 Genomes data build.
awk '{print$2,$4}' HapMap_MDS.map > buildhapmap.txt
# buildhapmap.txt contains one SNP-id and physical position per line.

plink --bfile 1kG_MDS6 --update-map buildhapmap.txt --make-bed --out 1kG_MDS7
# 1kG_MDS7 and HapMap_MDS now have the same build.

## Merge the HapMap and 1000 Genomes data sets

# Prior to merging 1000 Genomes data with the HapMap data we want to make sure that the files are mergeable, for this we conduct 3 steps:
# 1) Make sure the reference genome is similar in the HapMap and the 1000 Genomes Project datasets.
# 2) Resolve strand issues.
# 3) Remove the SNPs which after the previous two steps still differ between datasets.

# The following steps are maybe quite technical in terms of commands, but we just compare the two data sets and make sure they correspond.

# 1) set reference genome 
awk '{print$2,$5}' 1kG_MDS7.bim > 1kg_ref-list.txt
plink --bfile HapMap_MDS --reference-allele 1kg_ref-list.txt --make-bed --out HapMap-adj
# The 1kG_MDS7 and the HapMap-adj have the same reference genome for all SNPs.
# This command will generate some warnings for impossible A1 allele assignment.

# 2) Resolve strand issues.
# Check for potential strand issues.
awk '{print$2,$5,$6}' 1kG_MDS7.bim > 1kGMDS7_tmp
awk '{print$2,$5,$6}' HapMap-adj.bim > HapMap-adj_tmp
sort 1kGMDS7_tmp HapMap-adj_tmp |uniq -u > all_differences.txt
# 1624 differences between the files, some of these might be due to strand issues.

## Flip SNPs for resolving strand issues.
# Print SNP-identifier and remove duplicates.
awk '{print$1}' all_differences.txt | sort -u > flip_list.txt
# Generates a file of 812 SNPs. These are the non-corresponding SNPs between the two files. 
# Flip the 812 non-corresponding SNPs. 
plink --bfile HapMap-adj --flip flip_list.txt --reference-allele 1kg_ref-list.txt --make-bed --out corrected_hapmap

# Check for SNPs which are still problematic after they have been flipped.
awk '{print$2,$5,$6}' corrected_hapmap.bim > corrected_hapmap_tmp
sort 1kGMDS7_tmp corrected_hapmap_tmp |uniq -u  > uncorresponding_SNPs.txt
# This file demonstrates that there are 84 differences between the files.

# 3) Remove problematic SNPs from HapMap and 1000 Genomes.
awk '{print$1}' uncorresponding_SNPs.txt | sort -u > SNPs_for_exlusion.txt
# The command above generates a list of the 42 SNPs which caused the 84 differences between the HapMap and the 1000 Genomes data sets after flipping and setting of the reference genome.

# Remove the 42 problematic SNPs from both datasets.
plink --bfile corrected_hapmap --exclude SNPs_for_exlusion.txt --make-bed --out HapMap_MDS2
plink --bfile 1kG_MDS7 --exclude SNPs_for_exlusion.txt --make-bed --out 1kG_MDS8

# Merge HapMap with 1000 Genomes Data.
plink --bfile HapMap_MDS2 --bmerge 1kG_MDS8.bed 1kG_MDS8.bim 1kG_MDS8.fam --allow-no-sex --make-bed --out MDS_merge2

# Note, we are fully aware of the sample overlap between the HapMap and 1000 Genomes datasets. However, for the purpose of this tutorial this is not important.

## Perform MDS on HapMap-CEU data anchored by 1000 Genomes data.
# Using a set of pruned SNPs
plink --bfile MDS_merge2 --extract indepSNP.prune.in --genome --out MDS_merge2
plink --bfile MDS_merge2 --read-genome MDS_merge2.genome --cluster --mds-plot 10 --out MDS_merge2


### MDS-plot

# Download the file with population information of the 1000 genomes dataset.
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/20100804.ALL.panel
# The file 20100804.ALL.panel contains population codes of the individuals of 1000 genomes.

# Convert population codes into superpopulation codes (i.e., AFR,AMR,ASN, and EUR).
awk '{print$1,$1,$2}' 20100804.ALL.panel > race_1kG.txt
sed 's/JPT/ASN/g' race_1kG.txt>race_1kG2.txt
sed 's/ASW/AFR/g' race_1kG2.txt>race_1kG3.txt
sed 's/CEU/EUR/g' race_1kG3.txt>race_1kG4.txt
sed 's/CHB/ASN/g' race_1kG4.txt>race_1kG5.txt
sed 's/CHD/ASN/g' race_1kG5.txt>race_1kG6.txt
sed 's/YRI/AFR/g' race_1kG6.txt>race_1kG7.txt
sed 's/LWK/AFR/g' race_1kG7.txt>race_1kG8.txt
sed 's/TSI/EUR/g' race_1kG8.txt>race_1kG9.txt
sed 's/MXL/AMR/g' race_1kG9.txt>race_1kG10.txt
sed 's/GBR/EUR/g' race_1kG10.txt>race_1kG11.txt
sed 's/FIN/EUR/g' race_1kG11.txt>race_1kG12.txt
sed 's/CHS/ASN/g' race_1kG12.txt>race_1kG13.txt
sed 's/PUR/AMR/g' race_1kG13.txt>race_1kG14.txt

# Create a racefile of your own data.
awk '{print$1,$2,"OWN"}' HapMap_MDS.fam>racefile_own.txt

# Concatenate racefiles.
cat race_1kG14.txt racefile_own.txt | sed -e '1i\FID IID race' > racefile.txt

# Generate population stratification plot.
Rscript MDS_merged.R 
# The output file MDS.pdf demonstrates that our ?own? data falls within the European group of the 1000 genomes data. Therefore, we do not have to remove subjects.
# For educational purposes however, we give scripts below to filter out population stratification outliers. Please execute the script below in order to generate the appropriate files for the next tutorial.

## Exclude ethnic outliers.
# Select individuals in HapMap data below cut-off thresholds. The cut-off levels are not fixed thresholds but have to be determined based on the visualization of the first two dimensions. To exclude ethnic outliers, the thresholds need to be set around the cluster of population of interest.
awk '{ if ($4 <-0.04 && $5 >0.03) print $1,$2 }' MDS_merge2.mds > EUR_MDS_merge2

# Extract these individuals in HapMap data.
plink --bfile HapMap_3_r3_12 --keep EUR_MDS_merge2 --make-bed --out HapMap_3_r3_13
# Note, since our HapMap data did include any ethnic outliers, no individuls were removed at this step. However, if our data would have included individuals outside of the thresholds we set, then these individuals would have been removed.

## Create covariates based on MDS.
# Perform an MDS ONLY on HapMap data without ethnic outliers. The values of the 10 MDS dimensions are subsequently used as covariates in the association analysis in the third tutorial.
plink --bfile HapMap_3_r3_13 --extract indepSNP.prune.in --genome --out HapMap_3_r3_13
plink --bfile HapMap_3_r3_13 --read-genome HapMap_3_r3_13.genome --cluster --mds-plot 10 --out HapMap_3_r3_13_mds

# Change the format of the .mds file into a plink covariate file.
awk '{print$1, $2, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13}' HapMap_3_r3_13_mds.mds > covar_mds.txt

# The values in covar_mds.txt will be used as covariates, to adjust for remaining population stratification, in the third tutorial where we will perform a genome-wide association analysis.

##########################################################################################################################################################################

## CONGRATULATIONS you have succesfully controlled your data for population stratification!

# For the next tutorial you need the following files:
# - HapMap_3_r3_13 (the bfile, i.e., HapMap_3_r3_13.bed,HapMap_3_r3_13.bim,and HapMap_3_r3_13.fam
# - covar_mds.txt



```

# break tutorial 2, now tutor 3

```{bash,eval=FALSE}
################ Explanation of the main script ##########################

# Just as with the previous tutorials, this tutorial can be completed simply by copy-and-pasting all commands from this ?main script? into the Unix terminal.
# For a theoretical background on these method we refer to the accompanying article entitled ?A tutorial on conducting Genome-Wide-Association Studies: Quality control and statistical analysis? (https://www.ncbi.nlm.nih.gov/pubmed/29484742).
# In order to run this script you need the following files from the previous tutorial: covar_mds.txt and HapMap_3_r3_13 (bfile, i.e., HapMap_3_r3_13.bed, HapMap_3_r3_13.bim, HapMap_3_r3_13.fam).

###########################################################
### Association analyses ###

# For the association analyses we use the files generated in the previous tutorial (population stratification), named: HapMap_3_r3_13 (with .bed, .bim, and .fam. extensions) and covar_mds.txt

# Copy the bfile HapMap_3_r3_13 from the previous tutorial to the current directory.
# cp HOME/{user}/{path/ 2_Population_stratification}/HapMap_3_r3_13.* HOME/{user}/{path/3_Main_script_association_GWAS.txt}
# Copy the covar_mds.txt from the previous tutorial in the current directory.
# cp HOME/{user}/{path/ 2_Population_stratification}/covar_mds.txt HOME/{user}/{path/3_Main_script_association_GWAS.txt}

cp 1_QC_GWAS/HapMap_3_r3_12.* 3_Association_GWAS
```
```{bash,eval=FALSE}
cd 3_Association_GWAS
# mv HapMap_3_r3_12.* HapMap_3_r3_13.*
# rename 's/HapMap_3_r3_12./HapMap_3_r3_13./' * # cant rename
```

# now finsh this, go plink
```{bash,eval=FALSE}
# For binary traits.
cd 3_Association_GWAS
# assoc
plink --bfile HapMap_3_r3_13 --assoc --out assoc_results
# Note, the --assoc option does not allow to correct covariates such as principal components (PC's)/ MDS components, which makes it less suited for association analyses.
```


# assoc_results.assoc
/home/wangzhe/projects/20220629_GWA_tutorial/3_Association_GWAS/assoc_results.assoc

rsync -avzP wangzhe@172.16.55.11:/home/wangzhe/projects/20220629_GWA_tutorial/3_Association_GWAS/assoc_results.assoc  ~/Desktop

```{r}
library(data.table)
library(tidyverse)
data <- read.delim("/home/wangzhe/projects/20220629_GWA_tutorial/3_Association_GWAS/assoc_results.assoc") # not ok | ' '*n
data1 <- read.table("/home/wangzhe/projects/20220629_GWA_tutorial/3_Association_GWAS/assoc_results.assoc",header = T) # ok,but title.
# data1 10e-2 then save
data2 <- data1 %>% 
  filter(P<10e-2)
write_delim(data2, "/home/wangzhe/projects/20220629_GWA_tutorial/3_Association_GWAS/assoc_results.assoc",col_names = T) #

```




```{bash,eval=FALSE}
# logistic 
# We will be using 10 principal components as covariates in this logistic analysis. We use the MDS components calculated from the previous tutorial: covar_mds.txt.
plink --bfile HapMap_3_r3_13 --covar covar_mds.txt --logistic --hide-covar --out logistic_results
# Note, we use the option -?hide-covar to only show the additive results of the SNPs in the output file.

# Remove NA values, those might give problems generating plots in later steps.
awk '!/'NA'/' logistic_results.assoc.logistic > logistic_results.assoc_2.logistic

# The results obtained from these GWAS analyses will be visualized in the last step. This will also show if the data set contains any genome-wide significant SNPs.

# Note, in case of a quantitative outcome measure the option --logistic should be replaced by --linear. The use of the --assoc option is also possible for quantitative outcome measures (as metioned previously, this option does not allow the use of covariates).

#################################################################

# Multiple testing
# There are various way to deal with multiple testing outside of the conventional genome-wide significance threshold of 5.0E-8, below we present a couple. 

#adjust
plink --bfile HapMap_3_r3_13 -assoc --adjust --out adjusted_assoc_results
# This file gives a Bonferroni corrected p-value, along with FDR and others.


## Permutation
# This is a computational intensive step. Further pros and cons of this method, which can be used for association and dealing with multiple testing, are described in our article corresponding to this tutorial (https://www.ncbi.nlm.nih.gov/pubmed/29484742).
# The reduce computational time we only perform this test on a subset of the SNPs from chromosome 22.
# The EMP2 collumn provides the for multiple testing corrected p-value.

# Generate subset of SNPs
awk '{ if ($4 >= 21595000 && $4 <= 21605000) print $2 }' HapMap_3_r3_13.bim > subset_snp_chr_22.txt
# Filter your bfile based on the subset of SNPs generated in the step above.
plink --bfile HapMap_3_r3_13 --extract subset_snp_chr_22.txt --make-bed --out HapMap_subset_for_perm
# Perform 1000000 perrmutations.
plink --bfile HapMap_subset_for_perm --assoc --mperm 1000000 --out subset_1M_perm_result

# Order your data, from lowest to highest p-value.
sort -gk 4 subset_1M_perm_result.assoc.mperm > sorted_subset.txt
# Check ordered permutation results
head sorted_subset.txt

#####################################################################

# Generate Manhattan and QQ plots.

# These scripts assume R >= 3.0.0.
# If you changed the name of the .assoc file or to the assoc.logistic file, please assign those names also to the Rscripts for the Manhattan and QQ plot, otherwise the scripts will not run.

# The following Rscripts require the R package qqman, the scripts provided will automatically download this R package and install it in /home/{user}/ . Additionally, the scripts load the qqman library and can therefore, similar to all other Rscript on this GitHub page, be executed from the command line.
# This location can be changed to your desired directory

Rscript --no-save Manhattan_plot.R
Rscript --no-save QQ_plot.R

# Please read below when you encountered an error:
# Note, the mirror used to download the package qqman can no longer by active, which will result in an error (so below for specific error).
# If you encounter this error, please contact me at a.t.marees@amc.uva.nl.
# This error can simply be resolved by changing the addresses in the scripts: Manhattan_plot.R and QQ_plot.R.
# Simply change the address (http://cran...) in line below, in both Rscripts (Manhattan_plot.R and QQ_plot.R) with (for example) https://cran.univ-paris1.fr/ .
# install.packages("qqman",repos="http://cran.cnr.berkeley.edu/",lib="~" ) # location of installation can be changed but has to correspond with the library location

# Example error:
# "Error in library("qqman", lib.loc = "-") :
#	there is no package called 'qqman'
#Execution halted"

#######################################################

## CONGRATULATIONS you have succesfully conducted a GWAS analyses!!

# If you are also interested in learning how to conduct a polygenic risk score (PRS) analysis please see our fourth tutorial.
# The tutorial explaining PRS is independent from the previous tutorials.

```




## Execution of tutorial 4

4_ PRS.doc works independently from the other tutorials. After downloading 4_ PRS.doc, you can run the script, without the need for unzipping, in a directory of choice.
